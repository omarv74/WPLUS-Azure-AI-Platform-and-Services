{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2e86a0d",
   "metadata": {},
   "source": [
    "# Quick Start Guide - Azure AI Foundry\n",
    "\n",
    "This notebook provides a hands-on introduction to Azure AI Foundry. You'll learn how to:\n",
    "1. Initialize the AI Project client\n",
    "2. List available models\n",
    "3. Create a simple chat completion request\n",
    "4. Create a basic AI agent\n",
    "5. Handle basic error scenarios\n",
    "\n",
    "## Prerequisites\n",
    "- Completed environment setup from previous notebook\n",
    "- Azure credentials configured\n",
    "- **azure-ai-projects** package version 1.0.0b12 or greater (`azure-ai-projects>=1.0.0b12`)\n",
    "- **Azure AI User role** assigned to your account for the Azure AI Foundry project\n",
    "  - See [Azure AI Foundry RBAC documentation](https://learn.microsoft.com/en-us/azure/ai-foundry/concepts/rbac-azure-ai-foundry?pivots=fdp-project) for more details on role assignments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b65a7d",
   "metadata": {},
   "source": [
    "## Import Required Libraries and Setup\n",
    "\n",
    "In the next cell, we'll:\n",
    "1. Import the necessary Azure SDK libraries for authentication and AI Projects\n",
    "2. Import standard Python libraries for environment variables and JSON handling\n",
    "3. Initialize Azure credentials using DefaultAzureCredential\n",
    "   - This will automatically use your logged-in Azure CLI credentials\n",
    "   - Alternatively, it can use other authentication methods like environment variables or managed identity\n",
    "\n",
    "## üîê Authentication Setup\n",
    "\n",
    "Before running the next cell, make sure you're authenticated with Azure CLI. Run this command in your terminal:\n",
    "\n",
    "```bash\n",
    "az login --use-device-code\n",
    "```\n",
    "\n",
    "This will provide you with a device code and URL to authenticate in your browser, which is useful for:\n",
    "- Remote development environments\n",
    "- Systems without a default browser\n",
    "- Corporate environments with strict security policies\n",
    "\n",
    "After successful authentication, you can proceed with the notebook cells below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a355de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from azure.identity import DefaultAzureCredential, AzureCliCredential, InteractiveBrowserCredential, ChainedTokenCredential\n",
    "from azure.ai.projects import AIProjectClient\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Initialize credentials with tenant-specific authentication (same as environment setup)\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Get the correct tenant ID from environment\n",
    "correct_tenant_id = os.getenv(\"TENANT_ID\")\n",
    "print(f\"üîë Using Tenant ID: {correct_tenant_id}\")\n",
    "\n",
    "# Create a credential chain with tenant-specific authentication\n",
    "def create_credential_chain_with_tenant():\n",
    "    \"\"\"Create a robust credential chain for authentication with specific tenant\"\"\"\n",
    "    try:\n",
    "        # Try Azure CLI first with the specific tenant\n",
    "        cli_credential = AzureCliCredential(tenant_id=correct_tenant_id)\n",
    "        \n",
    "        # Create a chained credential with fallbacks, all using the correct tenant\n",
    "        credential_chain = ChainedTokenCredential(\n",
    "            cli_credential,\n",
    "            InteractiveBrowserCredential(tenant_id=correct_tenant_id)\n",
    "        )\n",
    "        \n",
    "        return credential_chain\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Credential chain creation error: {e}\")\n",
    "        # Fallback to DefaultAzureCredential with tenant specified\n",
    "        return DefaultAzureCredential(tenant_id=correct_tenant_id)\n",
    "\n",
    "# Initialize credentials\n",
    "try:\n",
    "    credential = create_credential_chain_with_tenant()\n",
    "    \n",
    "    # Test the credential by getting a token for the correct tenant\n",
    "    test_token = credential.get_token(\"https://management.azure.com/.default\")\n",
    "    print(\"‚úÖ Successfully initialized Azure credentials with correct tenant!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Credential initialization failed: {str(e)}\")\n",
    "    print(f\"üí° Please run the authentication fix from the environment setup notebook first\")\n",
    "    credential = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd18d4ef",
   "metadata": {},
   "source": [
    "## Initialize AI Project Client\n",
    "\n",
    "> **Note:** Before proceeding, ensure you:\n",
    "> 1. Copy your `.env.example` file to `.env` from the root directory\n",
    "> 2. Update the project connection string in your `.env` file\n",
    "> 3. Have a Foundry Project already provisioned in Azure AI Foundry\n",
    "\n",
    "You can find your project connection string in [Azure AI Foundry](https://ai.azure.com) under your project's settings:\n",
    "\n",
    "<img src=\"images/proj-conn-string.png\" alt=\"Project Connection String Location\" width=\"600\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e5ebd2",
   "metadata": {},
   "source": [
    "## Creating the AI Project Client\n",
    "\n",
    "In the next cell, we'll create an AI Project client using the connection string from our `.env` file.\n",
    "> **Note:** This example uses the synchronous client. For higher performance scenarios, you can also create an asynchronous client by importing `asyncio` and using the async methods from `AIProjectClient`.\n",
    "\n",
    "The client will be used to:\n",
    "- Connect to your Azure AI Project using the connection string\n",
    "- Authenticate using Azure credentials\n",
    "- Enable making inference requests to your deployed models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41004b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "# Load environment variables from root directory\n",
    "notebook_path = Path().absolute()\n",
    "# Navigate to the root directory (up 3 levels: from Labs/Connection with AOAI/ to root)\n",
    "root_dir = notebook_path.parent.parent.parent\n",
    "env_path = root_dir / '.env'\n",
    "\n",
    "print(f\"üìÅ Looking for .env file at: {env_path}\")\n",
    "load_dotenv(env_path)\n",
    "\n",
    "try:\n",
    "    # Get the project connection string (which is actually the endpoint URL)\n",
    "    ai_foundry_project_endpoint = os.getenv(\"AI_FOUNDRY_PROJECT_ENDPOINT\")\n",
    "    if not ai_foundry_project_endpoint:\n",
    "        raise ValueError(\"AI_FOUNDRY_PROJECT_ENDPOINT not found in environment variables\")\n",
    "    \n",
    "    print(f\"üîó Project Connection: {ai_foundry_project_endpoint}\")\n",
    "    \n",
    "    # Create AIProjectClient as done in environment_setup (consistent with other notebooks)\n",
    "    client = AIProjectClient(\n",
    "        credential=credential,\n",
    "        endpoint=ai_foundry_project_endpoint\n",
    "    )\n",
    "    print(\"‚úì Successfully initialized AIProjectClient\")\n",
    "except Exception as e:\n",
    "    print(f\"√ó Error initializing client: {str(e)}\")\n",
    "    print(\"üí° Tip: Make sure your AI_FOUNDRY_PROJECT_ENDPOINT is set in the .env file at the root directory\")\n",
    "    print(f\"üí° Expected .env location: {env_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d77e602",
   "metadata": {},
   "source": [
    "## Create a Simple Completion\n",
    "Let's try a basic completion request:\n",
    "\n",
    "Now that we have an authenticated client, let's use it to make a chat completion request.\n",
    "The code below demonstrates how to:\n",
    "1. Get a ChatCompletionsClient from the azure-ai-inference package\n",
    "2. Use it to make a simple completion request\n",
    "\n",
    "We'll use the MODEL_DEPLOYMENT_NAME from our `.env` file, making it easy to switch between different\n",
    "deployed models without changing code. This could be an Azure OpenAI model, Microsoft model, or other providers\n",
    "that support chat completions.\n",
    "\n",
    "> Note: Make sure you have the azure-ai-inference package installed (from requirements.txt or as mentioned in [README.md](../README.md#-quick-start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3774ed1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.inference.models import UserMessage\n",
    "\n",
    "model_deployment_name = os.getenv(\"MODEL_DEPLOYMENT_NAME\")\n",
    "\n",
    "try:\n",
    "    # Use the correct Azure AI Projects SDK pattern\n",
    "    print(\"üîÑ Getting OpenAI client from Azure AI Project...\")\n",
    "    print(f\"ü§ñ Using model: {model_deployment_name}\")\n",
    "    \n",
    "    # Get OpenAI client using the correct method\n",
    "    openai_client = client.get_openai_client(api_version=\"2024-10-21\")\n",
    "    \n",
    "    # Create chat completion using OpenAI client pattern\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=model_deployment_name,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful health assistant\"},\n",
    "            {\"role\": \"user\", \"content\": \"How to be healthy in one sentence?\"}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ Successfully created chat completion!\")\n",
    "    print(f\"ü§ñ Assistant: {response.choices[0].message.content}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå An error occurred: {str(e)}\")\n",
    "    print(\"üí° Troubleshooting tips:\")\n",
    "    print(\"  - Ensure your Azure AI Project has OpenAI connections configured\")\n",
    "    print(\"  - Verify your MODEL_DEPLOYMENT_NAME is correctly deployed\")\n",
    "    print(\"  - Check that you have proper permissions to access the model\")\n",
    "    print(\"  - Make sure you're using the latest azure-ai-projects SDK version\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7864f9",
   "metadata": {},
   "source": [
    "## Create a simple Agent\n",
    "\n",
    "Using AI Agent Service, we can create a simple agent to answer health related questions.\n",
    "\n",
    "Let's explore Azure AI Agent Service, a powerful tool for building intelligent agents.\n",
    "\n",
    "Azure AI Agent Service is a fully managed service that helps developers build, deploy, and scale AI agents\n",
    "without managing infrastructure. It combines large language models with tools that allow agents to:\n",
    "- Answer questions using RAG (Retrieval Augmented Generation)\n",
    "- Perform actions through tool calling \n",
    "- Automate complex workflows\n",
    "\n",
    "The code below demonstrates how to:\n",
    "1. Create an agent with a code interpreter tool\n",
    "2. Create a conversation thread\n",
    "3. Send a message requesting BMI analysis \n",
    "4. Process the request and get results\n",
    "5. Save any generated visualizations to local files\n",
    "\n",
    "The agent will use the model specified in our .env file (MODEL_DEPLOYMENT_NAME) and will have access\n",
    "to a code interpreter tool for creating visualizations. This showcases how agents can combine\n",
    "natural language understanding with computational capabilities.\n",
    "\n",
    "> **Note:** Generated visualizations will be saved as PNG files in the same folder as this notebook.\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afb12b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.agents.models import CodeInterpreterTool\n",
    "\n",
    "try:\n",
    "    # Initialize the Code Interpreter Tool\n",
    "    code_interpreter = CodeInterpreterTool()\n",
    "    \n",
    "    # Create an AI agent with the code interpreter tool\n",
    "    agent = client.agents.create_agent(\n",
    "        model=model_deployment_name,\n",
    "        name=\"bmi-calculator\",\n",
    "        instructions=(\n",
    "            \"You are a health analyst who calculates BMI using US metrics (pounds, feet/inches). \"\n",
    "            \"Use average US female measurements: 5'4\\\" (69 inches) and 130 pounds. \"\n",
    "            \"Create a visualization showing where this BMI falls on the scale.\"\n",
    "        ),\n",
    "        tools=code_interpreter.definitions,\n",
    "        tool_resources=code_interpreter.resources,\n",
    "    )\n",
    "    \n",
    "    # Create a new conversation thread\n",
    "    thread = client.agents.threads.create()\n",
    "    \n",
    "    # Create a message requesting BMI analysis and visualization\n",
    "    message = client.agents.messages.create(\n",
    "        thread_id=thread.id,\n",
    "        role=\"user\",\n",
    "        content=(\n",
    "            \"Calculate BMI for an average US female (5'4\\\", 130 lbs). \"\n",
    "            \"Create a visualization showing where this BMI falls on the standard BMI scale from 15 to 35. \"\n",
    "            \"Include the standard BMI categories (Underweight, Normal, Overweight, Obese) in the visualization.\"\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Process the request by creating and running a thread run\n",
    "    run = client.agents.runs.create_and_process(thread_id=thread.id, agent_id=agent.id)\n",
    "    \n",
    "    # Get the agent's response\n",
    "    messages = client.agents.messages.list(thread_id=thread.id)\n",
    "    \n",
    "    # Print the assistant's response and save any images\n",
    "    for message in messages:\n",
    "        if message.role == \"assistant\":\n",
    "            # Print text content\n",
    "            for content_item in message.content:\n",
    "                if hasattr(content_item, 'text'):\n",
    "                    print(f\"ü§ñ Assistant: {content_item.text.value}\")\n",
    "            \n",
    "            # Save any image files using the correct API\n",
    "            for img in message.image_contents:\n",
    "                file_id = img.image_file.file_id\n",
    "                file_name = f\"bmi_analysis_{file_id}.png\"\n",
    "                \n",
    "                try:\n",
    "                    # Use the correct file saving method\n",
    "                    client.agents.files.save(file_id=file_id, file_name=file_name)\n",
    "                    print(f\"üìä Visualization saved as: {file_name}\")\n",
    "                    \n",
    "                except Exception as file_error:\n",
    "                    print(f\"‚ö†Ô∏è Could not save file {file_id}: {file_error}\")\n",
    "                    print(\"üí° You can view the file in the Azure AI Foundry portal\")\n",
    "            break\n",
    "    \n",
    "    # Cleanup by deleting the agent\n",
    "    client.agents.delete_agent(agent.id)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
